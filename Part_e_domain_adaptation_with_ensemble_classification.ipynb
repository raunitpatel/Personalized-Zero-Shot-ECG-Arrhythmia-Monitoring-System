{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb3ba36c",
   "metadata": {
    "papermill": {
     "duration": 0.004945,
     "end_time": "2025-03-27T18:18:58.324174",
     "exception": false,
     "start_time": "2025-03-27T18:18:58.319229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculate confusion matrices and performance metrics, domain adaptation with ensemble classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d951d45f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-27T18:18:58.333925Z",
     "iopub.status.busy": "2025-03-27T18:18:58.333602Z",
     "iopub.status.idle": "2025-03-27T18:19:03.368773Z",
     "shell.execute_reply": "2025-03-27T18:19:03.368080Z"
    },
    "papermill": {
     "duration": 5.041869,
     "end_time": "2025-03-27T18:19:03.370399",
     "exception": false,
     "start_time": "2025-03-27T18:18:58.328530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import scipy\n",
    "import torch.nn.functional as Func\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe6162c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.380387Z",
     "iopub.status.busy": "2025-03-27T18:19:03.379915Z",
     "iopub.status.idle": "2025-03-27T18:19:03.531697Z",
     "shell.execute_reply": "2025-03-27T18:19:03.530947Z"
    },
    "papermill": {
     "duration": 0.158247,
     "end_time": "2025-03-27T18:19:03.533219",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.374972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/kaggle/input/pytorch-sklearnn\")\n",
    "from pytorch_sklearn import NeuralNetwork\n",
    "from pytorch_sklearn.callbacks import WeightCheckpoint, Verbose, LossPlot, EarlyStopping, Callback, CallbackInfo\n",
    "from pytorch_sklearn.utils.func_utils import to_safe_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8ed3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.548761Z",
     "iopub.status.busy": "2025-03-27T18:19:03.548343Z",
     "iopub.status.idle": "2025-03-27T18:19:03.552290Z",
     "shell.execute_reply": "2025-03-27T18:19:03.551264Z"
    },
    "papermill": {
     "duration": 0.01377,
     "end_time": "2025-03-27T18:19:03.554023",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.540253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d98bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.567273Z",
     "iopub.status.busy": "2025-03-27T18:19:03.566983Z",
     "iopub.status.idle": "2025-03-27T18:19:03.570912Z",
     "shell.execute_reply": "2025-03-27T18:19:03.570116Z"
    },
    "papermill": {
     "duration": 0.012079,
     "end_time": "2025-03-27T18:19:03.572124",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.560045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce40800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.585212Z",
     "iopub.status.busy": "2025-03-27T18:19:03.584762Z",
     "iopub.status.idle": "2025-03-27T18:19:03.595236Z",
     "shell.execute_reply": "2025-03-27T18:19:03.594591Z"
    },
    "papermill": {
     "duration": 0.020187,
     "end_time": "2025-03-27T18:19:03.596537",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.576350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALID_PATIENT_IDS_PATH = '/kaggle/input/arrythmia-valid-patient-ids/patient_ids.pkl'\n",
    "valid_patients = read_data(VALID_PATIENT_IDS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7215d449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.605733Z",
     "iopub.status.busy": "2025-03-27T18:19:03.605504Z",
     "iopub.status.idle": "2025-03-27T18:19:03.608919Z",
     "shell.execute_reply": "2025-03-27T18:19:03.608277Z"
    },
    "papermill": {
     "duration": 0.009179,
     "end_time": "2025-03-27T18:19:03.610069",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.600890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/kaggle/input/arrythmia-dataset/dataset_training/dataset_beat_single_domain_adapted'\n",
    "TRIO_PATH = '/kaggle/input/arrythmia-dataset/dataset_training/dataset_beat_trios_domain_adapted'\n",
    "DICT_PATH = '/kaggle/input/dictionaries/dictionaries/dictionaries_5min_beats_single_sorted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033cac5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.619112Z",
     "iopub.status.busy": "2025-03-27T18:19:03.618862Z",
     "iopub.status.idle": "2025-03-27T18:19:03.622141Z",
     "shell.execute_reply": "2025-03-27T18:19:03.621541Z"
    },
    "papermill": {
     "duration": 0.009091,
     "end_time": "2025-03-27T18:19:03.623285",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.614194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAVE_PATH = '/kaggle/working/'\n",
    "save_dir = os.path.join(SAVE_PATH, \"nets\")\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "505f87d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.632351Z",
     "iopub.status.busy": "2025-03-27T18:19:03.632122Z",
     "iopub.status.idle": "2025-03-27T18:19:03.641524Z",
     "shell.execute_reply": "2025-03-27T18:19:03.640704Z"
    },
    "papermill": {
     "duration": 0.015233,
     "end_time": "2025-03-27T18:19:03.642740",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.627507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(patient_id, PATH):\n",
    "    \"\"\" \n",
    "    Reads the pickled ECG dataset from the given path for the given patient.\n",
    "    The file name must be \"patient_<patient_id>_dataset.pkl\".\n",
    "    \"\"\"\n",
    "    with open(os.path.join(PATH, f\"patient_{patient_id}_dataset.pkl\"), \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def load_dictionary(patient_id, PATH):\n",
    "    \"\"\"\n",
    "    Reads the pickled ECG dictionary from the given path for the given patient.\n",
    "    The file name must be \"patient_<patient_id>_dictionary.pkl\".\n",
    "    \"\"\"\n",
    "    with open(os.path.join(PATH, f\"patient_{patient_id}_dictionary.pkl\"), \"rb\") as f:\n",
    "        D = pickle.load(f)\n",
    "        F = scipy.linalg.null_space(D.T)\n",
    "        F = scipy.linalg.orth(F).T\n",
    "    return D, F\n",
    "\n",
    "    \n",
    "def dataset_to_tensors(dataset):\n",
    "    \"\"\"\n",
    "    Converts the given dataset to torch tensors in appropriate data types and shapes.\n",
    "    \"\"\"\n",
    "    dataset = dataset.copy()\n",
    "    train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "    dataset[\"train_X\"] = torch.Tensor(train_X).float().reshape(-1, 1, train_X.shape[1])\n",
    "    dataset[\"train_y\"] = torch.Tensor(train_y).long()\n",
    "    dataset[\"train_ids\"] = torch.Tensor(train_ids).long()\n",
    "    dataset[\"val_X\"] = torch.Tensor(val_X).float().reshape(-1, 1, val_X.shape[1])\n",
    "    dataset[\"val_y\"] = torch.Tensor(val_y).long()\n",
    "    dataset[\"val_ids\"] = torch.Tensor(val_ids).long()\n",
    "    dataset[\"test_X\"] = torch.Tensor(test_X).float().reshape(-1, 1, test_X.shape[1])\n",
    "    dataset[\"test_y\"] = torch.Tensor(test_y).long()\n",
    "    dataset[\"test_ids\"] = torch.Tensor(test_ids).long()\n",
    "    return dataset\n",
    "\n",
    "def add_dataset(patient_id, dataset, DATASET_PATH):\n",
    "    \"\"\"\n",
    "    Adds another dataset to an already existing one, increasing the number of channels.\n",
    "    \"\"\"\n",
    "    dataset = dataset.copy()\n",
    "    dataset_other = load_dataset(patient_id, DATASET_PATH)\n",
    "    dataset_other = dataset_to_tensors(dataset_other)\n",
    "    \n",
    "    assert torch.equal(dataset[\"train_y\"], dataset_other[\"train_y\"]), \"Training ground truths are different. Possibly shuffled differently.\"\n",
    "    assert torch.equal(dataset[\"val_y\"], dataset_other[\"val_y\"]), \"Validation ground truths are different. Possibly shuffled differently.\"\n",
    "    assert torch.equal(dataset[\"test_y\"], dataset_other[\"test_y\"]), \"Test ground truths are different. Possibly shuffled differently.\"\n",
    "    \n",
    "    train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "    train_other_X, _, _, val_other_X, _, _, test_other_X, _, _ = dataset_other.values()\n",
    "    dataset[\"train_X\"] = torch.cat((train_X, train_other_X), dim=1)\n",
    "    dataset[\"val_X\"] = torch.cat((val_X, val_other_X), dim=1)\n",
    "    dataset[\"test_X\"] = torch.cat((test_X, test_other_X), dim=1)\n",
    "    return dataset\n",
    "\n",
    "def load_N_channel_dataset(patient_id, DEFAULT_PATH, *PATHS):\n",
    "    \"\"\"\n",
    "    Loads the ECG dataset at the given path(s) for the given patient. Each dataset will be added as a new\n",
    "    channel in the given order.\n",
    "    \"\"\"\n",
    "    default_dataset = load_dataset(patient_id, DEFAULT_PATH)\n",
    "    default_dataset = dataset_to_tensors(default_dataset)\n",
    "    for PATH in PATHS:\n",
    "        default_dataset = add_dataset(patient_id, default_dataset, PATH)\n",
    "    return default_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a6bef70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.651825Z",
     "iopub.status.busy": "2025-03-27T18:19:03.651601Z",
     "iopub.status.idle": "2025-03-27T18:19:03.658549Z",
     "shell.execute_reply": "2025-03-27T18:19:03.657718Z"
    },
    "papermill": {
     "duration": 0.012782,
     "end_time": "2025-03-27T18:19:03.659850",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.647068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_error_one_patient(S, F, y=None, as_energy=False):\n",
    "    \"\"\"\n",
    "    Returns the error, E = S @ F.T\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        ECG signals of shape (N x K), where K is signal length.\n",
    "    F : array_like\n",
    "        Dictionary null-space of shape (M x K), where M is error signal length.\n",
    "    y : array_like\n",
    "        Array of labels of shape (N). If provided, errors are returned separately for healthy and arrhythmia.\n",
    "    as_energy : bool\n",
    "        If True, error energies are returned instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert F.shape[1] == S.shape[1], f\"F and S can't be matrix multiplied. Provide S as a matrix with shape (N x {F.shape[1]}).\"\n",
    "    assert y is None or len(np.unique(y)) == 2, f\"There must be 2 classes. Found {len(np.unique(y))} classes.\"\n",
    "    \n",
    "    E = S @ F.T\n",
    "    \n",
    "    if as_energy:\n",
    "        E = E.pow(2).sum(dim=1)\n",
    "    \n",
    "    if y is not None:\n",
    "        healthy = np.where(y == 0)[0]\n",
    "        arrhyth = np.where(y == 1)[0]\n",
    "\n",
    "        E_healthy = E[healthy]\n",
    "        E_arrhyth = E[arrhyth]\n",
    "        \n",
    "        return E, E_healthy, E_arrhyth\n",
    "    return E\n",
    "\n",
    "def get_error_per_patient(S, ids, DICT_PATH, y=None, as_energy=False):\n",
    "    \"\"\"\n",
    "    Returns the error, E = S_i @ F_i.T, where S_i and F_i are the signals and null-space of patient i.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    S : array_like\n",
    "        ECG signals of shape (N x K), where K is signal length.\n",
    "    ids : array_like\n",
    "        ids[i] is the id of the patient that S[i] belongs to.\n",
    "    DICT_PATH : str\n",
    "        Path to the folder that has the dictionary of the users.\n",
    "    y : array_like\n",
    "        Array of labels of shape (N). If provided, errors are returned separately for healthy and arrhythmia.\n",
    "    as_energy : bool\n",
    "        If True, error energies are returned instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, F = load_dictionary(ids[0], DICT_PATH)\n",
    "    F = torch.Tensor(F).float()\n",
    "    E_shape = S.shape[0] if as_energy else [S.shape[0], F.shape[0]]\n",
    "    Es = torch.empty(E_shape)\n",
    "    \n",
    "    for id_ in ids.unique():\n",
    "        _, F = load_dictionary(id_, DICT_PATH)\n",
    "        F = torch.Tensor(F).float()\n",
    "        idx = np.where(ids == id_)[0]\n",
    "        E = get_error_one_patient(S[ids == id_], F, as_energy=as_energy)\n",
    "        Es[idx] = E\n",
    "    \n",
    "    if y is not None:\n",
    "        healthy = np.where(y == 0)[0]\n",
    "        arrhyth = np.where(y == 1)[0]\n",
    "\n",
    "        E_healthy = Es[healthy]\n",
    "        E_arrhyth = Es[arrhyth]\n",
    "        \n",
    "        return Es, E_healthy, E_arrhyth\n",
    "    \n",
    "    return Es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16a788c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.668664Z",
     "iopub.status.busy": "2025-03-27T18:19:03.668451Z",
     "iopub.status.idle": "2025-03-27T18:19:03.673880Z",
     "shell.execute_reply": "2025-03-27T18:19:03.673254Z"
    },
    "papermill": {
     "duration": 0.011165,
     "end_time": "2025-03-27T18:19:03.675069",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.663904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExponentialFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.beta = X.mean()\n",
    "        self.fit_perf = np.sum(self.likelihood(X))\n",
    "    \n",
    "    def likelihood(self, X):\n",
    "        return scipy.stats.expon(scale=self.beta).pdf(X)\n",
    "\n",
    "class GaussianFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.mu = X.mean()\n",
    "        self.std = X.std()\n",
    "        self.fit_perf = np.sum(self.likelihood(X))\n",
    "    \n",
    "    def likelihood(self, X):\n",
    "        return scipy.stats.norm(loc=self.mu, scale=self.std).pdf(X)\n",
    "\n",
    "\n",
    "class BayesianFit:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X, model1, model2, prior1=1, prior2=1):\n",
    "        like1 = model1.likelihood(X) * prior1\n",
    "        like2 = model2.likelihood(X) * prior2\n",
    "        odd1 = like1 / like2\n",
    "        return odd1 / (1 + odd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea02540b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.683969Z",
     "iopub.status.busy": "2025-03-27T18:19:03.683765Z",
     "iopub.status.idle": "2025-03-27T18:19:03.689387Z",
     "shell.execute_reply": "2025-03-27T18:19:03.688732Z"
    },
    "papermill": {
     "duration": 0.011396,
     "end_time": "2025-03-27T18:19:03.690558",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.679162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_performance_metrics(cm):\n",
    "    \"\"\"\n",
    "    Calculates:\n",
    "        accuracy\n",
    "        true positive rate (recall, sensitivity)\n",
    "        specificity (1 - false positive rate)\n",
    "        positive predictive value (PPV, precision)\n",
    "        negative predictive value (NPV)\n",
    "        F1-score\n",
    "    from the given confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = np.asarray(cm).copy()\n",
    "    tp, fp, tn, fn = cm[0,0], cm[0,1], cm[1,1], cm[1,0]\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    rec = tp / (tp + fn)\n",
    "    spe = tn / (tn + fp)\n",
    "    pre = tp / (tp + fp)\n",
    "    npv = tn / (tn + fn)\n",
    "    f1 = (2 * pre * rec) / (pre + rec)\n",
    "    metrics = {\"acc\":acc, \"rec\":rec, \"spe\":spe, \"pre\":pre, \"npv\":npv, \"f1\":f1}\n",
    "    return metrics\n",
    "\n",
    "def get_confusion_matrix(pred_y, true_y, pos_is_zero=False):\n",
    "    \"\"\"\n",
    "    Calculates the confusion matrix for the given predictions and truth values. \n",
    "    \n",
    "    Set pos_is_zero to True if the positive sample's class index is 0.\n",
    "    In the case of our ECG work, positive means an abnormal beat, and has a class index of 1.\n",
    "    \"\"\"\n",
    "    pred_y = torch.as_tensor(pred_y, dtype=torch.long)\n",
    "    true_y = torch.as_tensor(true_y, dtype=torch.long)\n",
    "    vals = true_y + 2 * pred_y   # 0,0 -> 0    1,0 -> 1    0,1 -> 2    1,1 -> 3\n",
    "    cm = torch.zeros(4).long()  \n",
    "    cm += torch.bincount(vals, minlength=4)\n",
    "    cm = cm.reshape(2, 2)\n",
    "    \n",
    "    if not pos_is_zero:\n",
    "        return cm.flip((0, 1))\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2feb5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.699817Z",
     "iopub.status.busy": "2025-03-27T18:19:03.699577Z",
     "iopub.status.idle": "2025-03-27T18:19:03.704025Z",
     "shell.execute_reply": "2025-03-27T18:19:03.703408Z"
    },
    "papermill": {
     "duration": 0.010362,
     "end_time": "2025-03-27T18:19:03.705165",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.694803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_base_model(in_channels):\n",
    "    \"\"\"\n",
    "    Returns the model from paper: Personalized Monitoring and Advance Warning System for Cardiac Arrhythmias.\n",
    "    \"\"\"\n",
    "    # Input size: 128x1\n",
    "    # 128x1 -> 122x32 -> 40x32 -> 34x16 -> 11x16 -> 5x16 -> 1x16\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv1d(in_channels, 32, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Conv1d(32, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Conv1d(16, 16, kernel_size=7, padding=0, bias=True),\n",
    "        nn.MaxPool1d(3),\n",
    "        nn.Tanh(),\n",
    "        \n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear(16, 32, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(32, 2, bias=True),\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a46f49b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.713946Z",
     "iopub.status.busy": "2025-03-27T18:19:03.713744Z",
     "iopub.status.idle": "2025-03-27T18:19:03.717112Z",
     "shell.execute_reply": "2025-03-27T18:19:03.716434Z"
    },
    "papermill": {
     "duration": 0.009026,
     "end_time": "2025-03-27T18:19:03.718249",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.709223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = [-1]\n",
    "batch_sizes = [1024]\n",
    "confidences = [0, *np.linspace(0.5, 1, 51)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02d65f55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.727118Z",
     "iopub.status.busy": "2025-03-27T18:19:03.726878Z",
     "iopub.status.idle": "2025-03-27T18:19:03.730708Z",
     "shell.execute_reply": "2025-03-27T18:19:03.730109Z"
    },
    "papermill": {
     "duration": 0.00951,
     "end_time": "2025-03-27T18:19:03.731843",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.722333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_array_of_dict_of_confmat(arr):\n",
    "    return np.stack([np.stack(list(d.values())) for d in arr])\n",
    "\n",
    "def extract_array_of_dict_of_dict_of_confmat(arr):\n",
    "    return np.stack([np.stack([np.stack(list(d2.values())) for d2 in d1.values()]) for d1 in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5017316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.740942Z",
     "iopub.status.busy": "2025-03-27T18:19:03.740733Z",
     "iopub.status.idle": "2025-03-27T18:19:03.788581Z",
     "shell.execute_reply": "2025-03-27T18:19:03.787659Z"
    },
    "papermill": {
     "duration": 0.053886,
     "end_time": "2025-03-27T18:19:03.789944",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.736058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5391eee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T18:19:03.799855Z",
     "iopub.status.busy": "2025-03-27T18:19:03.799580Z",
     "iopub.status.idle": "2025-03-27T20:01:27.957484Z",
     "shell.execute_reply": "2025-03-27T20:01:27.956626Z"
    },
    "papermill": {
     "duration": 6144.184846,
     "end_time": "2025-03-27T20:01:27.979543",
     "exception": false,
     "start_time": "2025-03-27T18:19:03.794697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repeat 1 Progress: 100%|██████████| 34/34 [10:38<00:00, 18.77s/it]\n",
      "Repeat 2 Progress: 100%|██████████| 34/34 [10:08<00:00, 17.89s/it]\n",
      "Repeat 3 Progress: 100%|██████████| 34/34 [09:50<00:00, 17.37s/it]\n",
      "Repeat 4 Progress: 100%|██████████| 34/34 [10:08<00:00, 17.91s/it]\n",
      "Repeat 5 Progress: 100%|██████████| 34/34 [10:23<00:00, 18.35s/it]\n",
      "Repeat 6 Progress: 100%|██████████| 34/34 [10:07<00:00, 17.86s/it]\n",
      "Repeat 7 Progress: 100%|██████████| 34/34 [10:20<00:00, 18.25s/it]\n",
      "Repeat 8 Progress: 100%|██████████| 34/34 [10:16<00:00, 18.14s/it]\n",
      "Repeat 9 Progress: 100%|██████████| 34/34 [10:13<00:00, 18.05s/it]\n",
      "Repeat 10 Progress: 100%|██████████| 34/34 [10:15<00:00, 18.11s/it]\n"
     ]
    }
   ],
   "source": [
    "all_patient_cms = []\n",
    "all_cms = []\n",
    "all_weights = []\n",
    "all_confs = []\n",
    "repeats = 10\n",
    "\n",
    "for repeat in range(repeats):\n",
    "    patient_cms = {conf:{} for conf in confidences}\n",
    "    cm = {conf:torch.zeros(2, 2) for conf in confidences}\n",
    "    confs = []\n",
    "\n",
    "    for i, patient_id in tqdm(enumerate(valid_patients), total=len(valid_patients), desc=f\"Repeat {repeat+1} Progress\"):\n",
    "        dataset = load_N_channel_dataset(patient_id, DATASET_PATH, TRIO_PATH)\n",
    "        train_X, train_y, train_ids, val_X, val_y, val_ids, test_X, test_y, test_ids = dataset.values()\n",
    "\n",
    "        # FOR CONSULTING THROUGH ERROR ENERGY.\n",
    "        D, F = load_dictionary(patient_id, DICT_PATH)\n",
    "        D, F = torch.Tensor(D), torch.Tensor(F)\n",
    "\n",
    "        # CONSULTING EXPONENTIAL - GAUSSIAN.\n",
    "        BF = BayesianFit()\n",
    "        EF = ExponentialFit()\n",
    "        GF = GaussianFit()\n",
    "\n",
    "        # TRAIN ERROR\n",
    "        train_E, E_healthy, E_arrhyth = get_error_one_patient(train_X[:, 0, :].squeeze(), F, y=train_y, as_energy=True)\n",
    "\n",
    "        EF.fit(E_healthy)\n",
    "        GF.fit(E_arrhyth)\n",
    "        consult_train_y = torch.Tensor(BF.predict(train_E, EF, GF) <= 0.5).long()\n",
    "\n",
    "        # TEST ERROR\n",
    "        test_E = get_error_one_patient(test_X[:, 0, :].squeeze(), F, as_energy=True)\n",
    "\n",
    "        EF.fit(E_healthy)\n",
    "        GF.fit(E_arrhyth)\n",
    "        consult_test_y = torch.Tensor(BF.predict(test_E, EF, GF) <= 0.5).long()\n",
    "\n",
    "\n",
    "        # LOAD THE NEURAL NETWORK\n",
    "        model = get_base_model(in_channels=train_X.shape[1])\n",
    "        model = model.to(device)\n",
    "        crit = nn.CrossEntropyLoss()\n",
    "        optim = torch.optim.AdamW(params=model.parameters())\n",
    "\n",
    "        net = NeuralNetwork(model, optim, crit)\n",
    "        weight_checkpoint_val_loss = WeightCheckpoint(tracked=\"val_loss\", mode=\"min\")\n",
    "        early_stopping = EarlyStopping(tracked=\"val_loss\", mode=\"min\", patience=15)\n",
    "\n",
    "        net.fit(\n",
    "            train_X=train_X,\n",
    "            train_y=train_y,\n",
    "            validate=True,\n",
    "            val_X=val_X,\n",
    "            val_y=val_y,\n",
    "            max_epochs=max_epochs[0],\n",
    "            batch_size=batch_sizes[0],\n",
    "            use_cuda=True,\n",
    "            fits_gpu=True,\n",
    "            callbacks=[weight_checkpoint_val_loss, early_stopping],\n",
    "        )\n",
    "\n",
    "        net.load_weights(weight_checkpoint_val_loss)\n",
    "\n",
    "        # SAVE TRAINED WEIGHTS\n",
    "        NeuralNetwork.save_class(net, os.path.join(save_dir, f\"net_{repeat+1}_{patient_id}\"))\n",
    "\n",
    "        \n",
    "\n",
    "        # TEST PREDICTIONS AND PROBABILITIES.\n",
    "        pred_y = net.predict(test_X, batch_size=1024, use_cuda=True, fits_gpu=True, decision_func=lambda pred_y: pred_y.argmax(dim=1)).cpu()\n",
    "        prob_y = net.predict_proba(test_X).cpu()\n",
    "        softmax_prob_y = Func.softmax(prob_y, dim=1).max(dim=1).values\n",
    "\n",
    "        # USE THE CONFIDENCE CHOSEN ABOVE INSTEAD OF ITERATING ALL CONFIDENCES.\n",
    "        for conf in confidences:\n",
    "            low_confidence = softmax_prob_y < conf\n",
    "            high_confidence = softmax_prob_y >= conf\n",
    "\n",
    "            final_pred_y = torch.Tensor(np.select([low_confidence, high_confidence], [consult_test_y, pred_y])).long()\n",
    "            cm_exp = get_confusion_matrix(final_pred_y, test_y, pos_is_zero=False)\n",
    "\n",
    "            patient_cms[conf][patient_id] = cm_exp\n",
    "            cm[conf] += cm_exp\n",
    "                    \n",
    "    all_patient_cms.append(patient_cms)\n",
    "    all_cms.append(cm)\n",
    "    all_confs.append(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "044d7916",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.020717Z",
     "iopub.status.busy": "2025-03-27T20:01:28.020339Z",
     "iopub.status.idle": "2025-03-27T20:01:28.024106Z",
     "shell.execute_reply": "2025-03-27T20:01:28.023515Z"
    },
    "papermill": {
     "duration": 0.025604,
     "end_time": "2025-03-27T20:01:28.025212",
     "exception": false,
     "start_time": "2025-03-27T20:01:27.999608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    learning_rate=0.001,\n",
    "    max_epochs=max_epochs[0],\n",
    "    batch_size=batch_sizes[0],\n",
    "    optimizer=optim.__class__.__name__,\n",
    "    loss=crit.__class__.__name__,\n",
    "    early_stopping=\"true\",\n",
    "    checkpoint_on=weight_checkpoint_val_loss.tracked,\n",
    "    dataset=\"default+trio\",\n",
    "    info=\"Results replicated for GitHub, DA + Ensemble + All C.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfaff399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.065451Z",
     "iopub.status.busy": "2025-03-27T20:01:28.065239Z",
     "iopub.status.idle": "2025-03-27T20:01:28.071799Z",
     "shell.execute_reply": "2025-03-27T20:01:28.071209Z"
    },
    "papermill": {
     "duration": 0.028391,
     "end_time": "2025-03-27T20:01:28.073088",
     "exception": false,
     "start_time": "2025-03-27T20:01:28.044697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_cms = extract_array_of_dict_of_confmat(all_cms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c6969bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.113994Z",
     "iopub.status.busy": "2025-03-27T20:01:28.113769Z",
     "iopub.status.idle": "2025-03-27T20:01:28.119229Z",
     "shell.execute_reply": "2025-03-27T20:01:28.118550Z"
    },
    "papermill": {
     "duration": 0.027435,
     "end_time": "2025-03-27T20:01:28.120334",
     "exception": false,
     "start_time": "2025-03-27T20:01:28.092899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.99046916,\n",
       " 'rec': 0.9877559,\n",
       " 'spe': 0.99085206,\n",
       " 'pre': 0.93841344,\n",
       " 'npv': 0.99825925,\n",
       " 'f1': 0.9624526382226926}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_performance_metrics(all_cms.sum(axis=0)[0])  # only DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5433b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.161221Z",
     "iopub.status.busy": "2025-03-27T20:01:28.160990Z",
     "iopub.status.idle": "2025-03-27T20:01:28.165483Z",
     "shell.execute_reply": "2025-03-27T20:01:28.164846Z"
    },
    "papermill": {
     "duration": 0.02637,
     "end_time": "2025-03-27T20:01:28.166619",
     "exception": false,
     "start_time": "2025-03-27T20:01:28.140249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9473855,\n",
       " 'rec': 0.80160743,\n",
       " 'spe': 0.9679574,\n",
       " 'pre': 0.7792658,\n",
       " 'npv': 0.97188956,\n",
       " 'f1': 0.7902787546670186}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_performance_metrics(all_cms.sum(axis=0)[-1]) # only NPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36452899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.207160Z",
     "iopub.status.busy": "2025-03-27T20:01:28.206926Z",
     "iopub.status.idle": "2025-03-27T20:01:28.211729Z",
     "shell.execute_reply": "2025-03-27T20:01:28.211098Z"
    },
    "papermill": {
     "duration": 0.026194,
     "end_time": "2025-03-27T20:01:28.212973",
     "exception": false,
     "start_time": "2025-03-27T20:01:28.186779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9901866,\n",
       " 'rec': 0.9835072,\n",
       " 'spe': 0.9911291,\n",
       " 'pre': 0.9399242,\n",
       " 'npv': 0.99765724,\n",
       " 'f1': 0.9612219242026848}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_performance_metrics(all_cms[:, 1:-1, :, :].sum(axis=(0, 1))) # avg over quantized C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d1d5a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T20:01:28.254105Z",
     "iopub.status.busy": "2025-03-27T20:01:28.253887Z",
     "iopub.status.idle": "2025-03-27T20:01:29.391797Z",
     "shell.execute_reply": "2025-03-27T20:01:29.390841Z"
    },
    "papermill": {
     "duration": 1.159771,
     "end_time": "2025-03-27T20:01:29.393398",
     "exception": false,
     "start_time": "2025-03-27T20:01:28.233627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(SAVE_PATH, \"cms.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(all_cms, f)\n",
    "    \n",
    "with open(os.path.join(SAVE_PATH, \"config.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(config, f)\n",
    "    \n",
    "with open(os.path.join(SAVE_PATH, \"patient_cms.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(all_patient_cms, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7df5b",
   "metadata": {
    "papermill": {
     "duration": 0.019722,
     "end_time": "2025-03-27T20:01:29.433900",
     "exception": false,
     "start_time": "2025-03-27T20:01:29.414178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6975992,
     "sourceId": 11176910,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6976128,
     "sourceId": 11177092,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6976452,
     "sourceId": 11177520,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6984390,
     "sourceId": 11188224,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6155.357139,
   "end_time": "2025-03-27T20:01:31.082675",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-27T18:18:55.725536",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
